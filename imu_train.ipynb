{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         x     y  pressure      roll     pitch       yaw\n",
      "0    182.0  80.0    1122.0 -2.746521  1.025011 -0.618634\n",
      "1    182.0  80.0       0.0 -2.657336  1.154270 -0.406283\n",
      "2    182.0  80.0     563.0 -1.783907  1.263274  0.671600\n",
      "3    182.0  80.0     548.0 -2.604287  1.074945 -0.318286\n",
      "4    182.0  81.0     531.0 -2.451713  1.198036 -0.162468\n",
      "..     ...   ...       ...       ...       ...       ...\n",
      "713    NaN   NaN       NaN -2.713433  1.143323 -0.531934\n",
      "714    NaN   NaN       NaN -2.998732  1.153641 -1.083088\n",
      "715    NaN   NaN       NaN -2.713433  1.143323 -0.531934\n",
      "716    NaN   NaN       NaN -2.706826  0.849819 -0.393914\n",
      "717    NaN   NaN       NaN -2.723049  1.085116 -0.506370\n",
      "\n",
      "[718 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(r'merge_data.csv',sep=',',header='infer')\n",
    "print(data)\n",
    "\n",
    "# 移除缺失值\n",
    "data_clean = data.dropna(subset=['x', 'y', 'pressure', 'roll', 'pitch', 'yaw'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用glob方法来获取数据图片的所有路径\n",
    "all_imgs_path = glob.glob(r'/home/lyc/doc/AML_LAB/dataset(imu)/*/*.png')#数据文件夹路径，根据实际情况更改！\n",
    "#循环遍历输出列表中的每个元素，显示出每个图片的路径\n",
    "for var in all_imgs_path:\n",
    "    print(var)\n",
    "\n",
    "#利用自定义类Mydataset创建对象weather_dataset\n",
    "signature_dataset = Mydataset(all_imgs_path)\n",
    "print(len(signature_dataset)) #返回文件夹中图片总个数\n",
    "print(signature_dataset[12:15])#切片，显示第12至第十五张图片的路径\n",
    "sinature_datalodaer = torch.utils.data.DataLoader(signature_dataset, batch_size=5) #每次迭代时返回五个数据\n",
    "print(next(iter(sinature_datalodaer)))\n",
    "\n",
    "species = ['false','true']\n",
    "species_to_id = dict((c, i) for i, c in enumerate(species))\n",
    "print(species_to_id)\n",
    "id_to_species = dict((v, k) for k, v in species_to_id.items())\n",
    "print(id_to_species)\n",
    "all_labels = []\n",
    "#对所有图片路径进行迭代\n",
    "for img in all_imgs_path:\n",
    "    # 区分出每个img，应该属于什么类别\n",
    "    for i, c in enumerate(species):\n",
    "        if c in img:\n",
    "            all_labels.append(i)\n",
    "#print(all_labels) #得到所有标签\n",
    "            \n",
    "\n",
    "            \n",
    "# 对数据进行转换处理\n",
    "transform = transforms.Compose([\n",
    "                transforms.Resize((240,320)), #做的第一步转换\n",
    "                transforms.ToTensor() #第二步转换，作用：第一转换成Tensor，第二将图片取值范围转换成0-1之间，第三会将channel置前\n",
    "])\n",
    "\n",
    "class Mydatasetpro(data.Dataset):\n",
    "# 类初始化\n",
    "    def __init__(self, img_paths, labels, transform):\n",
    "        self.imgs = img_paths\n",
    "        self.labels = labels\n",
    "        self.transforms = transform\n",
    "# 进行切片\n",
    "    def __getitem__(self, index):                #根据给出的索引进行切片，并对其进行数据处理转换成Tensor，返回成Tensor\n",
    "        img = self.imgs[index]\n",
    "        label = self.labels[index]\n",
    "        pil_img = Image.open(img)                 #pip install pillow\n",
    "        data = self.transforms(pil_img)\n",
    "        return data, label\n",
    "# 返回长度\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "\n",
    "\n",
    "BATCH_SIZE = 10\n",
    "signature_dataset = Mydatasetpro(all_imgs_path, all_labels, transform)\n",
    "sinature_datalodaer = data.DataLoader(\n",
    "                            signature_dataset,\n",
    "                            batch_size=BATCH_SIZE,\n",
    "                            shuffle=True\n",
    ")\n",
    "\n",
    "imgs_batch, labels_batch = next(iter(sinature_datalodaer))\n",
    "print(imgs_batch.shape)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i, (img, label) in enumerate(zip(imgs_batch[:6], labels_batch[:6])):\n",
    "    img = img.permute(1, 2, 0).numpy()\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    plt.title(id_to_species.get(label.item()))\n",
    "    plt.imshow(img)\n",
    "plt.show()#展示图片"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mix",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
