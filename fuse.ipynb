{"cells":[{"cell_type":"code","execution_count":71,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["120\n","['/home/lyc/doc/AML_LAB/imu_data/False_10anson.csv', '/home/lyc/doc/AML_LAB/imu_data/False_10che.csv', '/home/lyc/doc/AML_LAB/imu_data/False_10xizhi.csv', '/home/lyc/doc/AML_LAB/imu_data/False_10zimo.csv', '/home/lyc/doc/AML_LAB/imu_data/False_1anson.csv', '/home/lyc/doc/AML_LAB/imu_data/False_1carol.csv', '/home/lyc/doc/AML_LAB/imu_data/False_1che.csv', '/home/lyc/doc/AML_LAB/imu_data/False_1owen.csv', '/home/lyc/doc/AML_LAB/imu_data/False_1xinlong.csv', '/home/lyc/doc/AML_LAB/imu_data/False_1xizhi.csv', '/home/lyc/doc/AML_LAB/imu_data/False_1zekai.csv', '/home/lyc/doc/AML_LAB/imu_data/False_1zimo.csv', '/home/lyc/doc/AML_LAB/imu_data/False_2anson.csv', '/home/lyc/doc/AML_LAB/imu_data/False_2carol.csv', '/home/lyc/doc/AML_LAB/imu_data/False_2che.csv', '/home/lyc/doc/AML_LAB/imu_data/False_2owen.csv', '/home/lyc/doc/AML_LAB/imu_data/False_2xinlong.csv', '/home/lyc/doc/AML_LAB/imu_data/False_2xizhi.csv', '/home/lyc/doc/AML_LAB/imu_data/False_2zekai.csv', '/home/lyc/doc/AML_LAB/imu_data/False_2zimo.csv', '/home/lyc/doc/AML_LAB/imu_data/False_3anson.csv', '/home/lyc/doc/AML_LAB/imu_data/False_3carol.csv', '/home/lyc/doc/AML_LAB/imu_data/False_3che.csv', '/home/lyc/doc/AML_LAB/imu_data/False_3owen.csv', '/home/lyc/doc/AML_LAB/imu_data/False_3xinlong.csv', '/home/lyc/doc/AML_LAB/imu_data/False_3xizhi.csv', '/home/lyc/doc/AML_LAB/imu_data/False_3zekai.csv', '/home/lyc/doc/AML_LAB/imu_data/False_3zimo.csv', '/home/lyc/doc/AML_LAB/imu_data/False_4anson.csv', '/home/lyc/doc/AML_LAB/imu_data/False_4carol.csv', '/home/lyc/doc/AML_LAB/imu_data/False_4che.csv', '/home/lyc/doc/AML_LAB/imu_data/False_4owen.csv', '/home/lyc/doc/AML_LAB/imu_data/False_4xinlong.csv', '/home/lyc/doc/AML_LAB/imu_data/False_4xizhi.csv', '/home/lyc/doc/AML_LAB/imu_data/False_4zekai.csv', '/home/lyc/doc/AML_LAB/imu_data/False_4zimo.csv', '/home/lyc/doc/AML_LAB/imu_data/False_5anson.csv', '/home/lyc/doc/AML_LAB/imu_data/False_5carol.csv', '/home/lyc/doc/AML_LAB/imu_data/False_5che.csv', '/home/lyc/doc/AML_LAB/imu_data/False_5owen.csv', '/home/lyc/doc/AML_LAB/imu_data/False_5xinlong.csv', '/home/lyc/doc/AML_LAB/imu_data/False_5xizhi.csv', '/home/lyc/doc/AML_LAB/imu_data/False_5zekai.csv', '/home/lyc/doc/AML_LAB/imu_data/False_5zimo.csv', '/home/lyc/doc/AML_LAB/imu_data/False_6anson.csv', '/home/lyc/doc/AML_LAB/imu_data/False_6che.csv', '/home/lyc/doc/AML_LAB/imu_data/False_6xizhi.csv', '/home/lyc/doc/AML_LAB/imu_data/False_6zimo.csv', '/home/lyc/doc/AML_LAB/imu_data/False_7anson.csv', '/home/lyc/doc/AML_LAB/imu_data/False_7che.csv', '/home/lyc/doc/AML_LAB/imu_data/False_7xizhi.csv', '/home/lyc/doc/AML_LAB/imu_data/False_7zimo.csv', '/home/lyc/doc/AML_LAB/imu_data/False_8anson.csv', '/home/lyc/doc/AML_LAB/imu_data/False_8che.csv', '/home/lyc/doc/AML_LAB/imu_data/False_8xizhi.csv', '/home/lyc/doc/AML_LAB/imu_data/False_8zimo.csv', '/home/lyc/doc/AML_LAB/imu_data/False_9anson.csv', '/home/lyc/doc/AML_LAB/imu_data/False_9che.csv', '/home/lyc/doc/AML_LAB/imu_data/False_9xizhi.csv', '/home/lyc/doc/AML_LAB/imu_data/False_9zimo.csv', '/home/lyc/doc/AML_LAB/imu_data/True_10anson.csv', '/home/lyc/doc/AML_LAB/imu_data/True_10che.csv', '/home/lyc/doc/AML_LAB/imu_data/True_10xizhi.csv', '/home/lyc/doc/AML_LAB/imu_data/True_10zimo.csv', '/home/lyc/doc/AML_LAB/imu_data/True_1anson.csv', '/home/lyc/doc/AML_LAB/imu_data/True_1carol.csv', '/home/lyc/doc/AML_LAB/imu_data/True_1che.csv', '/home/lyc/doc/AML_LAB/imu_data/True_1owen.csv', '/home/lyc/doc/AML_LAB/imu_data/True_1xinlong.csv', '/home/lyc/doc/AML_LAB/imu_data/True_1xizhi.csv', '/home/lyc/doc/AML_LAB/imu_data/True_1zekai.csv', '/home/lyc/doc/AML_LAB/imu_data/True_1zimo.csv', '/home/lyc/doc/AML_LAB/imu_data/True_2anson.csv', '/home/lyc/doc/AML_LAB/imu_data/True_2carol.csv', '/home/lyc/doc/AML_LAB/imu_data/True_2che.csv', '/home/lyc/doc/AML_LAB/imu_data/True_2owen.csv', '/home/lyc/doc/AML_LAB/imu_data/True_2xinlong.csv', '/home/lyc/doc/AML_LAB/imu_data/True_2xizhi.csv', '/home/lyc/doc/AML_LAB/imu_data/True_2zekai.csv', '/home/lyc/doc/AML_LAB/imu_data/True_2zimo.csv', '/home/lyc/doc/AML_LAB/imu_data/True_3anson.csv', '/home/lyc/doc/AML_LAB/imu_data/True_3carol.csv', '/home/lyc/doc/AML_LAB/imu_data/True_3che.csv', '/home/lyc/doc/AML_LAB/imu_data/True_3owen.csv', '/home/lyc/doc/AML_LAB/imu_data/True_3xinlong.csv', '/home/lyc/doc/AML_LAB/imu_data/True_3xizhi.csv', '/home/lyc/doc/AML_LAB/imu_data/True_3zekai.csv', '/home/lyc/doc/AML_LAB/imu_data/True_3zimo.csv', '/home/lyc/doc/AML_LAB/imu_data/True_4anson.csv', '/home/lyc/doc/AML_LAB/imu_data/True_4carol.csv', '/home/lyc/doc/AML_LAB/imu_data/True_4che.csv', '/home/lyc/doc/AML_LAB/imu_data/True_4owen.csv', '/home/lyc/doc/AML_LAB/imu_data/True_4xinlong.csv', '/home/lyc/doc/AML_LAB/imu_data/True_4xizhi.csv', '/home/lyc/doc/AML_LAB/imu_data/True_4zekai.csv', '/home/lyc/doc/AML_LAB/imu_data/True_4zimo.csv', '/home/lyc/doc/AML_LAB/imu_data/True_5anson.csv', '/home/lyc/doc/AML_LAB/imu_data/True_5carol.csv', '/home/lyc/doc/AML_LAB/imu_data/True_5che.csv', '/home/lyc/doc/AML_LAB/imu_data/True_5owen.csv', '/home/lyc/doc/AML_LAB/imu_data/True_5xinlong.csv', '/home/lyc/doc/AML_LAB/imu_data/True_5xizhi.csv', '/home/lyc/doc/AML_LAB/imu_data/True_5zekai.csv', '/home/lyc/doc/AML_LAB/imu_data/True_5zimo.csv', '/home/lyc/doc/AML_LAB/imu_data/True_6anson.csv', '/home/lyc/doc/AML_LAB/imu_data/True_6che.csv', '/home/lyc/doc/AML_LAB/imu_data/True_6xizhi.csv', '/home/lyc/doc/AML_LAB/imu_data/True_6zimo.csv', '/home/lyc/doc/AML_LAB/imu_data/True_7anson.csv', '/home/lyc/doc/AML_LAB/imu_data/True_7che.csv', '/home/lyc/doc/AML_LAB/imu_data/True_7xizhi.csv', '/home/lyc/doc/AML_LAB/imu_data/True_7zimo.csv', '/home/lyc/doc/AML_LAB/imu_data/True_8anson.csv', '/home/lyc/doc/AML_LAB/imu_data/True_8che.csv', '/home/lyc/doc/AML_LAB/imu_data/True_8xizhi.csv', '/home/lyc/doc/AML_LAB/imu_data/True_8zimo.csv', '/home/lyc/doc/AML_LAB/imu_data/True_9anson.csv', '/home/lyc/doc/AML_LAB/imu_data/True_9che.csv', '/home/lyc/doc/AML_LAB/imu_data/True_9xizhi.csv', '/home/lyc/doc/AML_LAB/imu_data/True_9zimo.csv']\n","120\n","{'False': 0, 'True': 1}\n","{0: 'False', 1: 'True'}\n","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"]}],"source":["import glob\n","import torch\n","from torch.utils import data\n","from PIL import Image\n","import numpy as np\n","from torchvision import transforms\n","import matplotlib.pyplot as plt\n","\n","\n","class Mydataset(data.Dataset):\n","    def __init__(self, imgs_path, imu_data_path, transform=None):\n","        \"\"\"\n","        imgs_path: 图像文件的路径列表。\n","        imu_data_path: IMU数据文件的路径，假设每个文件对应一个图像，并且文件名使得图像和数据可以匹配。\n","        transform: 应用于图像的转换。\n","        \"\"\"\n","        self.imgs_path = imgs_path\n","        self.imu_data_path = imu_data_path\n","        self.transform = transform\n","        # 假设IMU数据以某种方式存储，例如每个样本一个文件\n","        self.imu_data = [self._load_imu_data(p) for p in imu_data_path]\n","\n","    def __getitem__(self, index):\n","        # 加载图像\n","        img_path = self.imgs_path[index]\n","        img = Image.open(img_path).convert('RGB')  # 确保图像为RGB格式\n","        if self.transform:\n","            img = self.transform(img)\n","        \n","        # 加载IMU数据\n","        imu_data = self.imu_data[index]\n","        \n","        return img, imu_data\n","\n","    def __len__(self):\n","        return len(self.imgs_path)\n","\n","    def _load_imu_data(self, path):\n","        # 这里添加加载IMU数据的代码\n","        # 例如，如果IMU数据以文本形式存储，你可以这样加载它们：\n","        # 注意：你需要根据实际存储格式调整这部分代码\n","        imu_data = torch.tensor([0.0])  # 示例：用0.0初始化，实际应从文件加载\n","        return imu_data\n","\n","#使用glob方法来获取数据图片的所有路径\n","all_imgs_path = sorted(glob.glob(r'/home/lyc/doc/AML_LAB/img_data/*.png'))#数据文件夹路径，根据实际情况更改！\n","#循环遍历输出列表中的每个元素，显示出每个图片的路径\n","sample_size=0\n","for var in all_imgs_path:\n","    sample_size+=1\n","\n","print(sample_size)\n","\n","\n","#使用glob方法来获取数据图片的所有路径\n","all_imu_path = sorted(glob.glob(r'/home/lyc/doc/AML_LAB/imu_data/*.csv'))#数据文件夹路径，根据实际情况更改！\n","#循环遍历输出列表中的每个元素，显示出每个图片的路径\n","sample_size=0\n","for var in all_imu_path:\n","    sample_size+=1\n","\n","print(all_imu_path)\n","#利用自定义类Mydataset创建对象weather_dataset\n","signature_dataset = Mydataset(all_imgs_path,all_imu_path)\n","print(len(signature_dataset)) #返回文件夹中图片总个数\n","# print(signature_dataset[12:15])#切片，显示第12至第十五张图片的路径\n","sinature_datalodaer = torch.utils.data.DataLoader(signature_dataset, batch_size=5) #每次迭代时返回五个数据\n","# print(next(iter(sinature_datalodaer)))\n","\n","species = ['False','True']\n","species_to_id = dict((c, i) for i, c in enumerate(species))\n","print(species_to_id)\n","id_to_species = dict((v, k) for k, v in species_to_id.items())\n","print(id_to_species)\n","all_labels = []\n","#对所有图片路径进行迭代\n","for img in all_imgs_path:\n","    # 区分出每个img，应该属于什么类别\n","    for i, c in enumerate(species):\n","        if c in img:\n","            all_labels.append(i)\n","print(all_labels) #得到所有标签\n","            \n"]},{"cell_type":"code","execution_count":69,"metadata":{},"outputs":[],"source":["\n","\n","\n","\n","\n","# #使用glob方法来获取数据图片的所有路径\n","# all_imu_path = sorted(glob.glob(r'/home/lyc/doc/AML_LAB/imu_data/*.csv'))#数据文件夹路径，根据实际情况更改！\n","# #循环遍历输出列表中的每个元素，显示出每个图片的路径\n","# sample_size=0\n","# for var in all_imu_path:\n","#     sample_size+=1\n","\n","# print(all_imu_path)\n","\n","# #利用自定义类Mydataset创建对象weather_dataset\n","# imu_dataset = Mydataset(all_imu_path)\n","# print(len(imu_dataset)) #返回文件夹中图片总个数\n","# imu_datalodaer = torch.utils.data.DataLoader(imu_dataset, batch_size=5) #每次迭代时返回五个数据\n","# print(next(iter(imu_datalodaer)))\n","\n","# species = ['False','True']\n","# species_to_id = dict((c, i) for i, c in enumerate(species))\n","# print(species_to_id)\n","# id_to_species = dict((v, k) for k, v in species_to_id.items())\n","# print(id_to_species)\n","# all_imu_labels = []\n","# #对所有图片路径进行迭代\n","# for img in all_imu_path:\n","#     # 区分出每个img，应该属于什么类别\n","#     for i, c in enumerate(species):\n","#         if c in img:\n","#             all_imu_labels.append(i)\n","# print(all_imu_labels) #得到所有标签"]},{"cell_type":"code","execution_count":70,"metadata":{},"outputs":[{"ename":"TypeError","evalue":"default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'PIL.Image.Image'>","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[70], line 45\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# signature_dataset = SignatureDataset(all_imgs_path,all_imu_path,all_labels, transform)\u001b[39;00m\n\u001b[1;32m     39\u001b[0m sinature_datalodaer \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mDataLoader(\n\u001b[1;32m     40\u001b[0m                             signature_dataset,\n\u001b[1;32m     41\u001b[0m                             batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE,\n\u001b[1;32m     42\u001b[0m                             shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     43\u001b[0m )\n\u001b[0;32m---> 45\u001b[0m imgs_batch, imu_batch,labels_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msinature_datalodaer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28mprint\u001b[39m(imgs_batch\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     48\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m8\u001b[39m))\n","File \u001b[0;32m~/anaconda3/envs/mix/lib/python3.9/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[0;32m~/anaconda3/envs/mix/lib/python3.9/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n","File \u001b[0;32m~/anaconda3/envs/mix/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/anaconda3/envs/mix/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:265\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[1;32m    205\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;124;03m        Function that takes in a batch of data and puts the elements within the batch\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;124;03m        into a tensor with an additional outer dimension - batch size. The exact output type can be\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;124;03m            >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/anaconda3/envs/mix/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:142\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    139\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n","File \u001b[0;32m~/anaconda3/envs/mix/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:142\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    139\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n","File \u001b[0;32m~/anaconda3/envs/mix/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:150\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    147\u001b[0m             \u001b[38;5;66;03m# The sequence type may not support `__init__(iterable)` (e.g., `range`).\u001b[39;00m\n\u001b[1;32m    148\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]\n\u001b[0;32m--> 150\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(default_collate_err_msg_format\u001b[38;5;241m.\u001b[39mformat(elem_type))\n","\u001b[0;31mTypeError\u001b[0m: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'PIL.Image.Image'>"]}],"source":["\n","\n","class SignatureDataset(data.Dataset):\n","    def __init__(self, heatmap_paths, imu_data, labels, transform):\n","        \"\"\"\n","        heatmap_paths: 热图图像的路径列表\n","        imu_data: 对应的IMU数据，假设为一个Numpy数组，形状为(len(heatmap_paths), imu_features)\n","        labels: 标签列表\n","        transform: 对图像进行预处理的转换\n","        \"\"\"\n","        self.heatmap_paths = heatmap_paths\n","        self.imu_data = imu_data\n","        self.labels = labels\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.heatmap_paths)\n","\n","    def __getitem__(self, idx):\n","        image = Image.open(self.heatmap_paths[idx])\n","        if self.transform:\n","            image = self.transform(image)\n","        imu = self.imu_data[idx]\n","        label = self.labels[idx]\n","        return image, imu, label\n","    \n","\n","\n","\n","# 对数据进行转换处理\n","transform = transforms.Compose([\n","                transforms.Resize((240,320)), #做的第一步转换\n","                transforms.ToTensor() #第二步转换，作用：第一转换成Tensor，第二将图片取值范围转换成0-1之间，第三会将channel置前\n","])\n","\n","\n","\n","\n","BATCH_SIZE = 10\n","# signature_dataset = SignatureDataset(all_imgs_path,all_imu_path,all_labels, transform)\n","sinature_datalodaer = data.DataLoader(\n","                            signature_dataset,\n","                            batch_size=BATCH_SIZE,\n","                            shuffle=True\n",")\n","\n","imgs_batch, imu_batch,labels_batch = next(iter(sinature_datalodaer))\n","print(imgs_batch.shape)\n","\n","plt.figure(figsize=(12, 8))\n","for i, (img, label) in enumerate(zip(imgs_batch[:6], labels_batch[:6])):\n","    img = img.permute(1, 2, 0).numpy()\n","    plt.subplot(2, 3, i+1)\n","    plt.title(id_to_species.get(label.item()))\n","    plt.imshow(img)\n","plt.show()#展示图片\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["84\n","[1 1 0 1 0 0 0 1 1 0 0 0 0 1 1 0 1 0 0 1 1 1 0 0 0 0 0 1 0 1 0 0 0 1 1 0]\n","<__main__.SignatureDataset object at 0x7f5cdbed8d90>\n"]}],"source":["import pandas as pd \n","\n","#划分测试集和训练集\n","index = np.random.permutation(len(all_imgs_path))\n","\n","all_imgs_path = np.array(all_imgs_path)[index]\n","all_imus_path = np.array(all_imu_path)[index]\n","all_labels = np.array(all_labels)[index]\n","\n","#80% as train\n","s = int(len(all_imgs_path)*0.7)\n","print(s)\n","\n","train_imgs = all_imgs_path[:s]\n","train_imus = all_imus_path[:s]\n","train_labels = all_labels[:s]\n","\n","test_imgs = all_imgs_path[s:]\n","test_imus = all_imus_path[s:]\n","test_labels = all_labels[s:]\n","\n","\n","\n","\n","\n","print(test_labels)\n","train_ds = SignatureDataset(train_imgs,train_imus,all_labels, transform) #TrainSet TensorData\n","test_ds = SignatureDataset(test_imgs, test_imgs,test_labels, transform) #TestSet TensorData\n","\n","print(train_ds)\n","train_imgs = pd.get_dummies(train_imgs)\n","test_imgs = pd.get_dummies(test_imgs)\n","train_imus = pd.get_dummies(train_imus)\n","test_imus = pd.get_dummies(test_imus)\n","\n","\n","train_dl = data.DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)#TrainSet Labels\n","test_dl = data.DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=True)#TestSet Labels\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class SignatureModel(nn.Module):\n","    def __init__(self, imu_input_dim, num_classes):\n","        super(SignatureModel, self).__init__()\n","        # 第一个卷积层接受3个通道的输入\n","        self.conv1 = nn.Conv2d(3, 16, kernel_size=5, stride=1, padding=2)\n","        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n","        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2)\n","        # 经过两次池化后，图像尺寸减半两次，变为60x80\n","        # 计算全连接层的输入尺寸\n","        self.fc1_input_size = 32 * 60 * 80 + imu_input_dim\n","        self.fc1 = nn.Linear(self.fc1_input_size, 512)\n","        self.fc2 = nn.Linear(512, num_classes)\n","\n","    def forward(self, x, imu):\n","        x = self.pool(F.relu(self.conv1(x)))\n","        x = self.pool(F.relu(self.conv2(x)))\n","        x = x.view(-1, 32 * 60 * 80)  # 调整x的形状以匹配全连接层的输入\n","        x = torch.cat((x, imu), dim=1)  # 将处理后的图像特征和IMU数据拼接\n","        x = F.relu(self.fc1(x))\n","        x = self.fc2(x)\n","        return x\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def train_model(model, train_loader, criterion, optimizer, num_epochs=25):\n","    for epoch in range(num_epochs):\n","        model.train()\n","        running_loss = 0.0\n","        for images, imu_data, labels in train_loader:\n","            optimizer.zero_grad()\n","            outputs = model(images, imu_data)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","            running_loss += loss.item()\n","        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader)}')\n","\n","def validate_model(model, test_loader):\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for images, imu_data, labels in test_loader:\n","            outputs = model(images, imu_data)\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","    print(f'Accuracy on test set: {100 * correct / total}%')\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"ename":"TypeError","evalue":"expected Tensor as element 1 in argument 0, but got tuple","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[63], line 32\u001b[0m\n\u001b[1;32m     28\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[1;32m     29\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[0;32m---> 32\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[61], line 7\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, criterion, optimizer, num_epochs)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m images, imu_data, labels \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m      6\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m----> 7\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimu_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m      9\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n","File \u001b[0;32m~/anaconda3/envs/mix/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/anaconda3/envs/mix/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","Cell \u001b[0;32mIn[60], line 21\u001b[0m, in \u001b[0;36mSignatureModel.forward\u001b[0;34m(self, x, imu)\u001b[0m\n\u001b[1;32m     19\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x)))\n\u001b[1;32m     20\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m32\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m60\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m80\u001b[39m)  \u001b[38;5;66;03m# 调整x的形状以匹配全连接层的输入\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimu\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 将处理后的图像特征和IMU数据拼接\u001b[39;00m\n\u001b[1;32m     22\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1(x))\n\u001b[1;32m     23\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(x)\n","\u001b[0;31mTypeError\u001b[0m: expected Tensor as element 1 in argument 0, but got tuple"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","import torchvision.transforms as transforms\n","from torchvision.models import resnet18\n","from torch.utils.data import DataLoader\n","from torchvision import models\n","from torchsummary import summary\n","\n","\n","# 假设imu_input_dim是根据你的IMU数据确定的\n","imu_input_dim = 4 # 仅作为示例，具体值应根据你的数据调整\n","num_classes = 2\n","\n","# 创建模型实例\n","model = SignatureModel(imu_input_dim=imu_input_dim, num_classes=num_classes)\n","\n","# 假设你想要修改的是模型中名为fc2的全连接层\n","# 确保模型中有一个名为fc2的属性\n","if hasattr(model, 'fc2'):\n","    in_features = model.fc2.in_features\n","    model.fc2 = nn.Linear(in_features, num_classes)\n","else:\n","    print(\"Model doesn't have an attribute named 'fc2'. Please check the model definition.\")\n","\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","\n","train_model(model, train_dl, criterion, optimizer, num_epochs=25)"]}],"metadata":{"kernelspec":{"display_name":"mix","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"}},"nbformat":4,"nbformat_minor":2}
